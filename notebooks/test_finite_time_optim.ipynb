{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# main\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "\n",
    "# implementation\n",
    "from tools import make_regression_data, RegressionDataset, training_model\n",
    "from optimizers import FiniteTimeOptimizer\n",
    "\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train: (torch.Size([80, 10]), torch.Size([80, 1]))\n",
      "shape of test: (torch.Size([20, 10]), torch.Size([20, 1]))\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_FEATURES = 10\n",
    "X_train, X_test, y_train, y_test = make_regression_data(number_samples=100,\n",
    "                                                        number_features=NUMBER_OF_FEATURES,\n",
    "                                                        noise_value=5.5)\n",
    "print(f'shape of train: {X_train.shape, y_train.shape}\\nshape of test: {X_test.shape, y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example of train sample:\n",
      " (tensor([-0.5173, -0.5229,  1.5796,  2.2989,  1.4534, -0.3628, -0.2818,  1.4093,\n",
      "        -0.4455, -0.4202]), tensor([185.5551]))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RegressionDataset(features=X_train,\n",
    "                                  labels=y_train)\n",
    "test_dataset = RegressionDataset(features=X_test,\n",
    "                                 labels=y_test)\n",
    "print(f'example of train sample:\\n {train_dataset[19]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of batch: features - torch.Size([10, 10]) and labels - torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              shuffle=True,\n",
    "                              batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=BATCH_SIZE)\n",
    "batch_example_features, batch_example_labels  = next(iter(train_dataloader))\n",
    "print('shape of batch: features - {} and labels - {}'.format(batch_example_features.shape, batch_example_labels.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "simple_model = nn.Linear(in_features=10, out_features=1, bias=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss & metric & optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "metric_fn = R2Score()\n",
    "\n",
    "N_OF_BATCHES = 15\n",
    "optimizer = FiniteTimeOptimizer(params=simple_model.parameters(),\n",
    "                                lr=0.01,\n",
    "                                n_of_batches=N_OF_BATCHES)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 8 batches\n",
      "metric = 0.964\n",
      "loss = 2330.733\n",
      "finite-time estimation has been applied\n",
      "After 15 batches\n",
      "metric = 0.991\n",
      "loss = 613.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ffrankusha/work/university/research-work/optimizers/Finite_Time_Optimizer.py:91: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  integral, error = quad(func=square_det,\n"
     ]
    }
   ],
   "source": [
    "batch_number = 0\n",
    "while batch_number < N_OF_BATCHES:\n",
    "    simple_model.train()\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        predicted = simple_model(X_batch)\n",
    "        batch_number += 1\n",
    "        determinant = torch.det(X_batch)\n",
    "        inverse_batch = torch.linalg.inv(X_batch)\n",
    "        adjoin = determinant * inverse_batch\n",
    "        loss = loss_fn(adjoin @ predicted, adjoin @ y_batch)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backpropagation (compute gradient)\n",
    "        loss.backward()\n",
    "\n",
    "        # parameters update\n",
    "        optimizer.step(det_batch=determinant, t=batch_number)\n",
    "\n",
    "        if batch_number == N_OF_BATCHES:\n",
    "            print('finite-time estimation has been applied')\n",
    "            break\n",
    "    # validation\n",
    "    with torch.inference_mode():\n",
    "        metric, loss = 0.0, 0.0\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            predicted = simple_model(X_batch)\n",
    "            loss += loss_fn(predicted, y_batch)\n",
    "            metric += metric_fn(predicted, y_batch)\n",
    "        metric /= len(test_dataloader)\n",
    "        loss /= len(test_dataloader)\n",
    "\n",
    "        print(f\"After {batch_number} batches\")\n",
    "        print(f\"metric = {metric:.3f}\")\n",
    "        print(f\"loss = {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.991\n",
      "loss = 613.749\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    metric, loss = 0.0, 0.0\n",
    "    for X_batch, y_batch in test_dataloader:\n",
    "        predicted = simple_model(X_batch)\n",
    "        loss += loss_fn(predicted, y_batch)\n",
    "        metric += metric_fn(predicted, y_batch)\n",
    "    metric /= len(test_dataloader)\n",
    "    loss /= len(test_dataloader)\n",
    "\n",
    "    print(f\"R2 = {metric:.3f}\")\n",
    "    print(f\"loss = {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
